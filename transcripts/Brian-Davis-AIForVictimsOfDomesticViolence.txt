      "Artificial Intelligence for Victims of Domestic Violence."
      By: Brian Davis.
      >> Hello, everybody.  How are you guys doing?
      [Applause]
      Strange Loop.  I want to really thank you from the bottom of my heart for coming here today.  There are some really amazing talks, and probably if I wasn't here, I would probably be somewhere else watching one of those amazing talks, so you chose me, and I appreciate that.
      So I'm going to get started right away.  Let's see if I can see this, though.
      >> Software company axiom solves problems with the military and the business.  But the code that inhabits his name is Jael.
      >> Hello I'm Jael, I can help you find a safe place.  Get someone to alert police.
      >> So this is a chat bot, AI chat bot.  Basically, what it does is detect responses and input from the user, and it is far enough forgive back a response.
      >> Jael is made to help women.  Is accessed through a phone number and available on anything that sends digital messages.
      >> It can be on Facebook messenger, it can be on Skype, it can be on Alexa, anything that has messaging component to it.
      >> Okay.  Could you please provide your name and location so that we can send help your way.
      >> Brian gave her a voice for us.  But JL can be discrete.
      >> For me, this is someone who has a moment.  Maybe the abuser is in the other room and the abuser went out for an errand or, you know, whatever.  But they just have little amount of time.
      >> Programmers have the software ready to launch but Brian needs local domestic violence experts to help him teach Jael.
      >> I would ask you is it hard?  Is it hard to create an app that's smart enough to help?
      >> You know, I think it's hard because you have to engage so many people to be a part of the process, and that's what I'm hoping to do is to get the collaboration of the community.  The code isn't hard.  That's what we do.
      >> So a text from a desperate woman or man could soon be answered by artificial intelligence built to have the answers to provide the help and to quickly save lives.
      >> It's us.  So.  It's our collective thoughts and experiences being put to good use.
      >> So who is Jael?
      >> Jael is my daughter's name.  But it's also the name of a character in the Bible.  She's a woman, very strong woman that confronted the enemy and confronted them by herself.  She was very brave.  So.
      [Applause]
      >> So I'm going to start this off a little bit different because I get this great sense of coming to this place, coming to Missouri that there's a lot of history here.  And even when I was traveling across the cobblestone roads and some of the roads are exposed, you can see the cobblestone.  And what was conjuring in my mind was all of these images from the past.  And there are certain traditions where we -- I think it's very important and sacred to acknowledge the ancestors, those who came before us and for us to ask permission because their blood has spilled on this ground that they ask permission to give us the chance to speak and that our words would be acceptable to them.
      So I do ask that.  And even if you don't count sacred, then you know the history of this place is very complicated, and there's lots that have gone on here.  And Michael Brown isn't the only one that has fallen.  There have been other brown boys sitting on their knees with their eyes shut, hands behind their heads pinkies up and Toledo them on the grounds and call them all punks.  To make them bunch around the cast just the way he likes.  Just in boxer briefs or tighty whities and the white briefs catches them just so.  Tight against their chest but getting wider and the blood is soaking into the fabric and pooling on the ground, so he looks down automatic and the dark basement gets darker.  When it's wet, and he's losing his balance slow with his hands on his head, so his face hits first.  And his eyes go dead.  And the air sucked out of the world with his last breath.
      Times have made a choice of what to keep and what to throw away.  Everything in grain comes to a point so sharp, you could cut a piece of day, and it bleeds on the ground, keep your knees on the ground.  Keep your knees on the ground where they belong.
      That was a piece that David Digs recited and performed at the Brown baccalaureate this year, and when I watched that on YouTube, I was, like, man, I have to go to Brown.  I just love the intertwining of the humanities and all of the things that it means for us.  And I have signed up for Brown, actually.  I'm going to be doing a master's degree in cyber security.  And so that kind of brings me to the beginning of who am I insert impressive credentials here.
      So I'm software engineer.  I'm also a graduate of college.  I've been a software engineer for about 20 years I was very, very blessed and honored to have worked at Pandora for five years.  Before the republic and was one of the principle engineers working on what we call digital engagement.  So, basically, I was the jerk that was making it possible for all the ads to pop up.  But what I -- what we like to do at Pandora was to make the ads reengaging to make it part of the process of listening to music.  So this idea of, like, machine learning and data science and that being integrated into our user experience, like, I had no idea what the word data science meant when I was working at Pandora, but that's exactly what we were doing.  So it's very, very important to me that not only am I taking my experiences and my education and putting it to good use like the speaker said yesterday, but that it's also impacting lives.
      So that kind of goes to my next point of who am I?  I am a survivor of domestic violence.  So I know it's very rare, and you might look at me, like, that big guy with the dreadlocks and everything, you know what I'm saying?  How key be afraid of anyone?  And fear is a thing that has no color and no size, no any of that.  I mean, and also, it has no gender.  Even though more women are affected by domestic violence than anyone on the planet.  So being a survivor of it, I understand what goes on, and I understand this idea that there is a cascading failure that can happen in your life where, you know, you find yourself in a place, and you don't really know how you got there, and you don't really know how your choices contributed to the fact that you're in the spot right now.  And -- but you also blame yourself for all of the things that happen to you, you know?  There were several times that I would be kneeling in my bathroom saying the most powerful prayer that I knew.  Just trying to pass the time over when the yelling would stop.  And I would kneel there, and I would say out of the night that covers me workers' compensation black is the pit from pole to pole.  I thank whatever God's may be from my inconquerable soul.  I have not cried aloud, my hand is bloody yet unbowed.  Aluminums but the horror of the shape and yet the menace shall find me unafraid.  It matters not how straight the gate, how charge the punishment of the scroll.  I am the master of my fate.  I am the captain of my soul, and I would just keep saying it over and over again until the yelling would stop.  And then I would venture out and then think about all of the things that happened up to this point.
      And even years later after I escaped that very, very bad situation, then that same person would force their way into my house and threaten me to my face in front of my children, and I called the police, but they didn't come, and then I tried to get the 9-1-1 tape, but it was erased.
      See, my ex was an assistant DA, so it definitely knows no boundaries, any of it, all the violence, and we have to find a way to stop it.
      So this is my talk.  Welcome.  Sorry for the really dramatic intro.
      So I want to do one correction here, and I want to say that -- because I went to another talk.
      [Laughter]
      And so we're going to call this machine intelligence for victims of domestic violence.
      So what is Jael.ai?  We went over this quickly with the video.  It's a realtime making to understand inputs and route survivors to resources based on their situation.
      So just really simply, you know, someone is in a situation, and they need to get out, and they can text to the service and try to find that.  And so what I did was use a really simple natural language processing kind of like intent engine, API.ai, and I got a bunch of hotline scripts, so these are domestic violence hotline scripts that have been curated and in use of domestic violence from a psychological perspective.  People who are advocates, people who are survivors of domestic violence, and using this kind of, like, this -- all of this information to create these intents.
      So, you know, maybe you are messaging to Jael and you're saying, hey, I need some help or maybe you're saying I need someone to talk to.  So basically what it's doing is just trying to respond to every single one of those needs.  And it's going to get smarter and better.  I'm going to show you some other ways that it gets smarter in a second.
      So question is why are we doing this?
      Well, domestic violence is very bad.  And domestic violence is spreading.  It's alarming the amount that it's spreading.  The next -- I'm not going to kind of inundate you with statistics because I think it's out there.  You can find it if you want to know about it, and this talk is not necessarily about all of the statistics that are going on but about how we're using technology to stop it.  But this statistic right here, the 65% of women killed because of DV are murdered at the moment they try to leave.  That was 50% when I started on doing this research.  So it has gotten -- and then another study came out, and it's higher.
      So what does that mean?  It's, like, at that moment that they say they're going to leave, and it could be an hour, it can be 30 minutes, it can be, you know, a week or whatever.  You have a 65% chance of getting murdered in that moment.
      65%.
      So when I saw that and also the second -- also the last point right here where it says it's the third-leading cause of homelessness.  So if you do survive and get out.  Okay?  Then you probably would be homeless, like, on the street.  So remember when I talked about that cascading failure?  And we understand that in terms of technology, you know?  If you look at a network, you can understand what cascading failure means.  And if you look at biology, you can understand what cascading failure means.  If you look at structural engineering, you can understand what cascading failure means.
      It's this idea that one failure leads to another in that it weakens the structure so much that the whole thing could fall apart.  And this is what's happening to people's lives when they're living in situations where the person that they love and the person that they've put their trust in is basically trying to kill them.
      And, yeah.  So this is the reason why we're doing it.  I'm going to skip this for a second.  I'm going to go to this video real quick, and I'm going to play this.  I want you to watch carefully, and I want you to tell me when she's in danger.
      ¶¶¶
      >> When was she in danger?  Anyone have an idea?
      >> The moment she met him.
      >> Right.  The moment she met him, she was in danger.  It's not when, you know, she got mad or he got mad or anything like that.  The moment that she met him, she was in danger.
      Yeah.  So this is why we have to understand at a deeper level what this means because this is happening -- this affects people individually, but it also affects families.  Okay?  As a survivor, one of the things that my ex did to hurt me way after the fact is when I was able to get away from her, then she decided to brain wash my child.  My child was at the time 14.  She's now going to be a sophomore in college pretty soon, and I haven't talked to her since then.  And I have two boys as well that weren't affected by it, so -- but she was able to get to my daughter, and she was able to brain wash her into thinking that I was doing something to her when she was the one that was, like, breaking down doors and taking it off the hinges and yelling and screaming and threatening.  Waking up in the middle of the night talking over me writing journals saying that she would kill me, all of this stuff.
      So it has a cascading -- again, a cascading affect that it has on your life is tremendous.
      So the reason why I want to bring up that cascading effect is because if I were to tell you or any of you guys, software engineers or network engineers that, you know, you had to fortify a system; right?  That had the vulnerability to cascade failure, what would you do?  What would you do?  Any ideas?
      Isolate.  Isolate what?
      Right.  Right.  So if you know that this is a point that's going to fail, then you can say.  Okay.  I know this is going to fail, so I have a back up for this.  Kind of an idea of low balance or what else?  This is kind of hard, abstract question.
      Being preemptive.  Right.  So you know that this -- so when something fails, then you know that, you know, you have a back up.  But being preemptive and trying to kind of stay away from the failures, that's another thing.  I won't press you guys too much because I know it's a hard question.
      But this is the frustration that's happening right now in the DV community.  This idea that -- and my interfacing with them that we have these ways of dealing with DV, but they're very antiquated.  Okay?  This problem is not -- this problem is very hold.  But the solutions are very new.  So, you know, if you knew anything about, you know, women's history and I've been studying it more and more because I'm also the CTO of the woman's global leadership initiative, temporarily because I need to find a woman to take my place very dearly.
      But when you understand women's history and understand that this isn't something that started yesterday, and it has a very, very long history.  And in my research, I was very, very curious.  Like, when did this start?  Liked it was there a time when women actually had equal rights and were seen as equals with men?  Because it seems the further you go back in history, the worse and worse it gets.  You go back to the '70s, and they had to ask their husbands to get permission to get a credit card, and you go back to the 1800s and somewhere around there when man would actually come to court and be, like, well, she's my wife, I have the right to beat her and that kind of thing.  And that didn't end.  And it was only until the '90s that people were getting arrested for it.  That's crazy.
      So it became illegally I think in 1851, somewhere around there, and it wasn't until the 1990s that we began to see people actually get in trouble for it.  It's just completely crazy.  So as I went further and further and further back to realize that it was in ancient Greece when there were some cities where women had -- were seen as equals.  And some cities where they were not.  And it was all about the ideas that were being propagated at the time.  And the ideas -- and I really, really hate this because I'm a philosophy major, and I really loved Aristotle but Aristotle is one of the people who said, hey, women are not equals.  Women's should be kept in the house and women shouldn't have any rights.  They should be kept away from everyone.
      And it's a lot of complex and has to do with sexual freedom and that kind of thing and lineages and that kind of thing.
      But if I went further back into ancient Egypt and in ancient Egypt, they did actually have equality, and they were high priests and landowners and people that had, you know, equality.  And I'm not an Egyptologist or anything like that, so you could probably check me on that.  But, yeah.
      So the reason that we're tackling a very, very old problem.  Okay?  We're unwinding something that's very, very, very ancient, so when we're doing that, this whole idea of being preemptive and responding to failure in systems.  Okay?  Is a very, very important.  And this is why -- not only in the DV community, but in all of, like, nonprofits, we need to start using technology because the technology was designed to do -- is to do both of those things.  Be a back up plan.  Okay?  When something fails and to be preemptive when something is okay.
      So, yeah, Jael is not going to replace a real life person talking on the phone trying to guide someone through a process.  But it's another thing, another avenue, another way to stop that domino effect.  To be preemptive or to respond when something is completely failed.
      So here are some of the other things that we're doing.
      Predictive situational awareness and scenario curation.  So I told you I worked for Pandora, and I think working there and this whole idea of curation is embedded inside of me now.  It's this idea that we're going to start, you know, ingesting all of this information from 9-1-1 calls and all of the hotline calls and all of the times that women talk to these services and try to start deconstructing, like, the way that things happen, the way that things flaw.  So begin to know and understand what to look for and how to respond to those things.  And in the situations where people survived, what was the difference?  What was the action that was taken?
      Now, the reason why no one wants to touch this with a ten-foot pole is because it has legal liability written all over it.  Okay?  No one wants to be responsible for the fact that if AI says something or fails or has a crash and then, you know, someone dies, then what?  Then they're going to sue Jael.  I'm not afraid of that because, for me, that is basically being frozen by inaction because of fear of failure.  And we don't live any of our life like that in any other facet because we would just be stuck in our house and not move.  Okay?
      So we have to find a way around that.  We're going to find a way through it and to be able to -- and I think this is the good idea is that once we curate all of those calls and all of those hotline scripts.  Okay?  We're going to be better than even in some instances -- I mean, the same mistakes could happen with a person.  Okay?  If a hotline person comes in and is not in a good mood or they just spilt coffee on themselves; right?  Anything could happen.  So that could cause that same failure.
      So the idea here is that we're going to take all of that knowledge and put it at the fingerprints of Jael.  And this is what machine learning and AI and natural language processing is good for.
      So what are our challenges and what are our needs?
      We need money.  Right now, I've worked on this so much that I've neglected all of the other parts of my business.  I've basically, you know, I don't have any clients right now, as far as my dev shop that I run, and I've been working on this 24/7.  It's really, really important that we get some funding so that we can take care of the other two things up there.
      We need a lawyer or two.  Excuse me?  No, we're not.  No, we're not.  I didn't put it on Kickstarter because I feel like what we need to do is form a 51C3 and logistical work that needs to be done.  And I know what it's like to build something completely by yourself, and I'm not going to do that again.
      And all of these successful businesses, they have two people, holding each other accountable and working together.
      So that's another thing is we need partnerships, and we need engineers, and we need money.  I say that again.
      So, you know, this idea of using AI, this idea of using -- and this AI, it's not, like -- it can't be like Siri.  Like, oh, I didn't understand what you meant.  It has to 90%, 99% of the time understand what's going on.  And if it really doesn't understand, then what I want to do is also build into the system where if a conversation is going on and obviously is having problems and, you know, for a DV counselor to step into the conversation so, you know.  But think of all of the DV counselors that we would need on staff in a call center or somewhere, like, working, like, 24/7, like, it would be massive amounts of people.
      My goal right now is to make sure that it keeps on running without the need for a human being.
      I've written kind of sneaky Python script that is constantly, like, scraping the Web for resources, and it's putting all of the information in a database, so it's, like, you know, this is the DV resource, this is the location where it can go, the hours, this is the name of it, the address, this is the telephone number, this is the website, this is who you contact.  And it's very, very complex, actually, the way the whole entire thing works because you just can't put anybody in every DV center.  Okay?  There's some DV centers that handle children, some that don't, some that handle pets.
      So imagine having to make the choice of whether to, you know, stay and possibly get killed or, like, leave your dog, you know?  It's a very, very hard thing.  If you don't have any resources, if you don't really know what's going to happen to your pet, that person might kill your pet, you know?  People -- you know, people are evil.
      So it's one of those things it's more complex than just kind of, like, asking someone to go to a website.  Okay?  And a lot of people don't have the guts to get on the phone because, you know, I didn't have the guts to get on the phone.  I didn't have the guts to tell anyone.  This is actually the first time ever that I've spoken publicly about it like this.
      [Applause]
      So we want to -- so what I'm doing here is just creating another avenue for people to be able to speak out.  I'm right at the time limit I think or somewhere near there, and I want to definitely leave time for a discussion because I think that it's important, for me, at least to kind of hear back, and it could be comments, ideas, questions.  Like, go ahead.  Open it up.  Go ahead.
      >> List of possible decisions that Jael can recommend?
      >> Where do I get that list?  You said where do I get that list?
      >> What -- where does that come from?  The list of possible recommendations.
      >> Right.  Right.  So the question was where does the list of possible recommendations come from that Jael can undertake?  And that comes from the hotline scripts.  So the -- every person that goes through hotline training has to train for every kind of scenario, so that's where it comes from, initially.  And then also, that list is curated by a DV advocate or DV psychologist.  So this is someone -- so I've -- I think that's the really important part because there's a lot of -- there's some people that are trying to do AI for, like, therapy for, like, teenagers, and I was listening to one of the NPR specials about it, and it kind of failed pretty hard because the first thing that DV psychologist said to the AI was I hate my mom and the AI was, like, I don't understand.  I was, like -- that's the first thing that a child sometimes is having problems would say to, you know, an AI.  So that's one of the things that's really important to me is to make sure that as many intents as I can think of or add it to the system.  That's where machine learning comes in so that as it gets kind of -- this alpha use or beta use that, you know, it's being used by survivors that when it gets into production, it's going to be as prepared as possible.
      >> So is it in production?  And if so, do you have any numbers on YouTube?  
      >> So it's not in production.  First of all, it needs a lawyer.  But I kid you not, like, the minute -- before I had a prototype, was trying to contact me for an interview.  I had to scramble to get my prototype done.  People, they saw the news story, people started trying to use it, and I had to shut it down because it's not ready yet.
      So, yeah.  There's people clamoring to use it.  And people started asking me to help.  Which is heartbreaking you know what I'm saying?  And I was responding in the best with a I I knew how.  And then all of my -- so many friends that came out of the woodworks that said they have been abused and they were survivors I didn't even know.
      So, yeah, it's not in refresh your recollection yet, but we need to get it there fast.
      >> Can you talk about shaming a big factor in how domestic violence are handling situations and I'm curious how Jael, like, can she do anything to protect it?  And be more proactive about asking the right questions about what's going on?  Like, how do you handle the fact that this is a situation that people don't want to talk about that people often look back on details?
      >> Right.  This is the hard part.  So the hard part is that I think my sense is that in the beginning, it will be really, really hard for Jael to see any kind of, like, therapy.  Okay?  It's really meant in the beginning my ideas is to help people get out.  Okay?  Find resources.
      Once it detects a conversation that seems to be, like, okay.  Kind of how do I deal with the situation and the details of therapy, then it needs to refer them to get help because it's not going to be able to replace that counseling element.
      So, yeah, that's something that definitely will have to detect.  And what it's really trying to do is figure out is how eminent the danger is.  Because if they're trying to find a way to escape, then it's pretty bad.
      >> Have you looked into possibly having a channel, like, talking in code to people?  Because I know instances where people use iCloud and the abuser will have phones cloned.
      >> Right.  So that's a very good point, and this is the reason why I chose this setup through text messaging.  I know that iCloud, you know, is going to kind of screw with that.  But it's even more -- it's the easiest thing that you can delete and then not have to worry about reinstalling it or putting it on again.  And then when you start texting again -- so this is another benefit of having an AI doing the work is that if you called into a DV center, and you got someone on the phone, and you're talking with them, then you had to hang up.  Okay?  Because your abuser came back.  And then you had to call back in again.  Who knows if you're going to get that same person.  Who knows if the person that you get is going to remember, you know, all of what happened.  If they're taking notes or not or recording the call or who knows.
      So with Jael, they can pick the conversation back up like nothing ever happened.
      The iCloud challenge is going to be hard.  But -- and people do destroy devices.  That's a very common thing that happens in domestic violence is that's the first thing that gets destroyed is a device.  As I said, it's not a silver bullet, but it's an avenue.  So we'll have to work around those challenges.
      >> Jael to send the person a message and -- [Inaudible]
      >> I think that will be hard.  I think it's possible for Jael to someone else.  And I think that, you know, it's an interesting question to -- if you're not ready for help and someone comes and, you know, intervenes, you know, how do you respond to that?  People will respond differently.  I don't think creating any hard-fast rule of, like, yes or no would be appropriate, like, for me, at least.  It takes laugh thought and, unfortunately, some risk taking.  Way in the back.
      [Question off mic]
      >> If you want to donate, we do have a website that has donate on there, and I'm definitely not going to, you know -- I don't want to put pressure on you guys to, like, donate.  Whatever.  But if you want to, it's Jael.ai, and you'll find the link to donate there.
      We're training right now.  We're training right now with survivors, and the hotline scripts.  So it's not live in the sense that it's open to the whole entire world, but it's available to us so that we can -- and these are just survivors that -- with friends and that kind of thing.  And me myself as a survivor, so it's not a very formal process, but it's something that's going on for a while.  And what I'll do is I'll have a list of -- I'll list out a conversation, and then I'll give it to someone and say what does this look like?  It's, like, oh, you forgot about this.  And these people who are trained to understand DV, like, you know, scenarios.
      >> Once Jael helps the victim get a resource, would it be possible for the resource to then have access to the conversation so that they can rehash everything?  Like, a counselor could look it up and say this is what happened on Jael and have an action plan?
      >> Right.  So this is actually very important, and this is why we need a lawyer and the partnerships because there's lots of privacy concerns there, you know?  They have to give -- they have to give permission for that conversation to be shared, just like anything else.  And -- but if, you know, I really don't want to start off a conversation with a disclaimer, like, you are giving Jael the right -- you know, that would be -- that would kind of kill the vibe right there.  I want to be able to do this in a way that makes sense.  And this is one of the reasons, again, that I'm, you know, for me, cyber security is a human right.  And the Brown program that I'm enrolling in is all about not just about the technology but also about policy, so it's pretty important.
      Go ahead.
      >> Did you open source the code for Jael?
      >> It will be open source.  Yeah.  But I need an organization to do that with.  Way in the back.
      >> Yeah.  So.  One, I think designed this as a virtual system.  Do you have anybody with computational linguistics background or computational models of conversation that have been involved in --
      >> Yeah.  So part of the impressive credential stuff that I didn't mention is that a lot of the work that I've done after Pandora has been for our U.S. military intelligence.  And I've designed systems that, you know, everyone knows about the whole, like, prism thing and all of that stuff and digesting all of the information.  So, basically -- I didn't do that work.  But what I did was I developed systems for agencies to create analytical tools and then share those analytical tools across agencies, and it's called the big data platform.
      So you can look that up.  But, yeah, so I have worked with a lot of the machine-learning stuff for stuff that seems to me like a zillion times harder to analyze than this.  And then I also worked on something called ark angel, and that's a pretty interesting tool because if you ever watch Jason Borne or the Borne identity or something like that, and they have a map of a city, and they're zooming in and plugging in the cameras.  That software is pretty much real.  And I helped build it.  And, basically, what it does is ingests all of this information, and then it can actually do more than what you see on TV.  It's literally, like, a Google map for, like, threats.  And so what it's doing is trying to figure out, like, okay.  If you go from here to here, what's your chances of being attacked?  And then you can scroll the scrub bar back and go back in time, forward in time, and all of this stuff.  And ingesting huge amounts of data from, like, social media and agencies and all of the stuff like that.
      >> What would be the initial partnership look like?
      >> Right.  So when this aired -- before this aired, I was trying to get ahold of an organization in Sacramento called weave.  And they're the top dog in the sense of helping women and being there for women, and they get a lot of funding from everywhere.  And they didn't want to return any of our phone calls or e-mails.
      And then I asked Christina to, you know, advocate for me with them, and then I finally got them in a room.  And they listened to me, and then, you know, kind of like the tech phobia came up of is this going to replace this?  And I tried to explain them most empathetic way I knew how.  But it never followed up.  So organizations like that is what we need onboard.  But I'll be happy with anyone.  Like, an individual from that organization or just a person that's done it in the past.
      But those partnerships with those types of organizations that get a lot of money from the Federal Government, from private organizations, those are going to be the ones that are going to help us.  Because they have already fought the fight with, like, police and all of the agencies around protecting women's information and protecting women's rights, so they're going to be the best people to be on our team.
      Go ahead.
      >> Snapchat cloud?
      >> Making a what?
      >> A Snapchat.
      >> A Snapchat version?
      >> Yeah, I think it could be created around that.  As I said, I'm not going to close any door about the whole cascading failure thing.  The more places that you could use this as a back up.  As long as we don't put people in more danger.  And we don't know, you know?  We have to test this out.  But I think that I wouldn't rule it completely out, but I would be very careful with it.  I think we're pretty much out of time, and I want to thank you so much for being a part of this, and if you have any questions, I'm here or on the Slack channel.  Thank you very much.
      [Applause]
      Captions provided by @chaselfrazier and @whitecoatcapxg.
